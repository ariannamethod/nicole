#!/usr/bin/env python3
"""
Nicole2Nicole - –ú–æ–¥—É–ª—å –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –≤–µ—Å–æ–≤
–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–º–µ—Ä—Ç–∏/–ø–µ—Ä–µ—Ä–æ–∂–¥–µ–Ω–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤.
–£—á–∏—Ç—Å—è –Ω–∞ –ª–æ–≥–∞—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏ —ç–≤–æ–ª—é—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.
"""

import sqlite3
import json
import time
import threading
import math
import random
import sys
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import h2o
# import nicole  # –£–±–∏—Ä–∞–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–π –∏–º–ø–æ—Ä—Ç

@dataclass 
class LearningPattern:
    """–ü–∞—Ç—Ç–µ—Ä–Ω –æ–±—É—á–µ–Ω–∏—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏"""
    input_pattern: str
    output_pattern: str
    metrics_context: Dict
    architecture_context: Dict
    success_score: float
    frequency: int = 1
    
class Nicole2NicoleCore:
    """–Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, memory_db: str = "nicole_memory.db", knowledge_file: str = "nicole_learned_knowledge.json"):
        self.memory_db = memory_db
        self.knowledge_file = knowledge_file  # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: Auto-save —Ñ–∞–π–ª
        self.learning_patterns = {}
        self.evolution_patterns = {}
        self.architecture_preferences = {}
        self.learning_lock = threading.Lock()
        self.is_learning = False
        self.learning_cycles = 0  # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –°—á–µ—Ç—á–∏–∫ —Ü–∏–∫–ª–æ–≤ –¥–ª—è auto-save

        # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: Auto-load –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        if os.path.exists(self.knowledge_file):
            print(f"[Nicole2Nicole] Loading previous knowledge from {self.knowledge_file}...")
            self.import_learned_knowledge(self.knowledge_file)
        
    def analyze_conversation_logs(self, limit: int = 1000) -> List[LearningPattern]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        conn = sqlite3.connect(self.memory_db)
        cursor = conn.cursor()
        
        cursor.execute("""
        SELECT user_input, nicole_output, metrics, transformer_config, timestamp
        FROM conversations 
        ORDER BY timestamp DESC 
        LIMIT ?
        """, (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        patterns = []
        for row in rows:
            user_input, nicole_output, metrics_str, config_str, timestamp = row
            
            try:
                metrics = json.loads(metrics_str)
                config = json.loads(config_str)
                
                # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –æ–±—É—á–µ–Ω–∏—è
                pattern = LearningPattern(
                    input_pattern=self._extract_input_pattern(user_input),
                    output_pattern=self._extract_output_pattern(nicole_output),
                    metrics_context=metrics,
                    architecture_context=config,
                    success_score=self._calculate_success_score(metrics)
                )
                
                patterns.append(pattern)
                
            except Exception as e:
                print(f"[Nicole2Nicole] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–∞: {e}")
                
        return patterns
        
    def _extract_input_pattern(self, user_input: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞"""
        words = user_input.lower().split()
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π
        if any(word in words for word in ['–ø—Ä–∏–≤–µ—Ç', 'hello', 'hi', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π']):
            return "greeting"
        elif any(word in words for word in ['–ø–æ–∫–∞', 'bye', 'goodbye', '—É–≤–∏–¥–∏–º—Å—è']):
            return "farewell"  
        elif any(word in words for word in ['–∫–∞–∫', '–¥–µ–ª–∞', '–∂–∏–∑–Ω—å', '–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ']):
            return "status_inquiry"
        elif any(word in words for word in ['—á—Ç–æ', '—Ä–∞—Å—Å–∫–∞–∂–∏', '–æ–±—ä—è—Å–Ω–∏', '–æ–ø–∏—à–∏']):
            return "information_request"
        elif any(word in words for word in ['–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–æ—Ç—á–µ–≥–æ']):
            return "reasoning_request"
        elif len(words) > 10:
            return "long_message"
        elif len(words) < 3:
            return "short_message"
        else:
            return "general_conversation"
            
    def _extract_output_pattern(self, nicole_output: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ –æ—Ç–≤–µ—Ç–∞ Nicole —á–µ—Ä–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ë–ï–ó –®–ê–ë–õ–û–ù–û–í!)"""
        words = nicole_output.lower().split()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω—É –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–Ω–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ!)
        word_count = len(words)
        has_question = '?' in nicole_output

        if word_count > 15:
            return "detailed_response"
        elif has_question:
            return "question_back"
        elif word_count < 5:
            return "brief_response"
        else:
            return "general_response"
            
    def _calculate_success_score(self, metrics: Dict) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        try:
            entropy = metrics.get('entropy', 0.5)
            perplexity = metrics.get('perplexity', 1.0)
            resonance = metrics.get('resonance', 0.3)
            coherence = metrics.get('coherence', 0.5)
            engagement = metrics.get('engagement', 0.5)
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
            score = (
                entropy * 0.2 +
                (1.0 / max(0.1, perplexity)) * 0.3 +
                resonance * 0.3 +
                coherence * 0.1 +
                engagement * 0.1
            )
            
            return min(1.0, max(0.0, score))
            
        except Exception:
            return 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            
    def learn_from_patterns(self, patterns: List[LearningPattern]):
        """–û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"""
        with self.learning_lock:
            self.is_learning = True
            
            try:
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ —Ç–∏–ø–∞–º
                pattern_groups = {}
                for pattern in patterns:
                    key = (pattern.input_pattern, pattern.output_pattern)
                    if key not in pattern_groups:
                        pattern_groups[key] = []
                    pattern_groups[key].append(pattern)
                    
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
                for (input_type, output_type), group in pattern_groups.items():
                    self._analyze_pattern_group(input_type, output_type, group)
                    
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–≤–æ–ª—é—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
                self._analyze_architecture_evolution(patterns)
                
                print(f"[Nicole2Nicole] –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –Ω–∞ {len(patterns)} –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö")
                
            finally:
                self.is_learning = False
                
    def _analyze_pattern_group(self, input_type: str, output_type: str, patterns: List[LearningPattern]):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—É –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        if len(patterns) < 2:
            return
            
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        avg_metrics = {}
        metric_keys = ['entropy', 'perplexity', 'resonance', 'coherence', 'engagement']
        
        for key in metric_keys:
            values = []
            for pattern in patterns:
                if key in pattern.metrics_context:
                    values.append(pattern.metrics_context[key])
            if values:
                avg_metrics[key] = sum(values) / len(values)
                
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞
        best_patterns = sorted(patterns, key=lambda p: p.success_score, reverse=True)[:3]
        best_architectures = [p.architecture_context for p in best_patterns]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω
        pattern_key = f"{input_type}::{output_type}"
        self.learning_patterns[pattern_key] = {
            'avg_metrics': avg_metrics,
            'best_architectures': best_architectures,
            'frequency': len(patterns),
            'avg_success': sum(p.success_score for p in patterns) / len(patterns)
        }
        
        print(f"[Nicole2Nicole] –ü–∞—Ç—Ç–µ—Ä–Ω {pattern_key}: {len(patterns)} –ø—Ä–∏–º–µ—Ä–æ–≤, —É—Å–ø–µ—à–Ω–æ—Å—Ç—å {self.learning_patterns[pattern_key]['avg_success']:.3f}")
        
    def _analyze_architecture_evolution(self, patterns: List[LearningPattern]):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–≤–æ–ª—é—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä"""
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        arch_performance = {}
        
        for pattern in patterns:
            arch = pattern.architecture_context
            for param, value in arch.items():
                if param not in arch_performance:
                    arch_performance[param] = []
                arch_performance[param].append((value, pattern.success_score))
                
        # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        for param, value_scores in arch_performance.items():
            if len(value_scores) < 5:
                continue
                
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
            sorted_values = sorted(value_scores, key=lambda x: x[1], reverse=True)
            top_20_percent = sorted_values[:max(1, len(sorted_values) // 5)]
            
            # –ù–∞—Ö–æ–¥–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω –ª—É—á—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            top_values = [v[0] for v in top_20_percent]
            
            if isinstance(top_values[0], (int, float)):
                min_val = min(top_values)
                max_val = max(top_values)
                avg_val = sum(top_values) / len(top_values)
                
                self.architecture_preferences[param] = {
                    'min': min_val,
                    'max': max_val,
                    'avg': avg_val,
                    'samples': len(top_values)
                }
                
        print(f"[Nicole2Nicole] –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è {len(self.architecture_preferences)} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
    def suggest_architecture_improvements(self, current_arch: Dict, conversation_context: str) -> Dict:
        """
        –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è + exploration noise

        ANTI-OVERFITTING: –¥–æ–±–∞–≤–ª—è–µ—Ç 10% —à–∞–Ω—Å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        """
        if not self.learning_patterns or not self.architecture_preferences:
            return current_arch

        improved_arch = current_arch.copy()

        # EXPLORATION NOISE: 10% —à–∞–Ω—Å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∑–∞—Å—Ç—Ä–µ–≤–∞–Ω–∏–µ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –æ–ø—Ç–∏–º—É–º–µ
        exploration_probability = 0.1

        if random.random() < exploration_probability:
            # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            explorable_params = [p for p in improved_arch.keys()
                               if isinstance(improved_arch[p], (int, float))]

            if explorable_params:
                param_to_explore = random.choice(explorable_params)
                current_value = improved_arch[param_to_explore]

                # –°–ª—É—á–∞–π–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ ¬±20%
                noise_factor = random.uniform(0.8, 1.2)
                improved_arch[param_to_explore] = current_value * noise_factor

                print(f"[Nicole2Nicole:Exploration] üé≤ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ '{param_to_explore}': "
                      f"{current_value:.3f} ‚Üí {improved_arch[param_to_explore]:.3f}")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑—É—á–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
        for param, preferences in self.architecture_preferences.items():
            if param in improved_arch:
                current_val = improved_arch[param]
                
                # –î–≤–∏–≥–∞–µ–º—Å—è –∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É
                if isinstance(current_val, (int, float)):
                    target_val = preferences['avg']
                    
                    # –ü–ª–∞–≤–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∫ —Ü–µ–ª–∏
                    if current_val < preferences['min']:
                        improved_arch[param] = min(preferences['max'], current_val * 1.1)
                    elif current_val > preferences['max']:
                        improved_arch[param] = max(preferences['min'], current_val * 0.9)
                    else:
                        # –ú–µ–ª–∫–∏–µ —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                        noise = random.uniform(-0.05, 0.05)
                        improved_arch[param] = current_val * (1 + noise)
                        
        return improved_arch
        
    def suggest_response_strategy(self, user_input: str, current_metrics: Dict) -> str:
        """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑—É—á–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        input_pattern = self._extract_input_pattern(user_input)
        
        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        matching_patterns = []
        for pattern_key, pattern_data in self.learning_patterns.items():
            if pattern_key.startswith(input_pattern + "::"):
                matching_patterns.append((pattern_key, pattern_data))
                
        if not matching_patterns:
            return "general_response"
            
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
        best_pattern = max(matching_patterns, key=lambda x: x[1]['avg_success'])
        output_pattern = best_pattern[0].split("::")[-1]
        
        return output_pattern
        
    def continuous_learning_loop(self):
        """
        –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: Auto-save –∫–∞–∂–¥—ã–µ 10 —Ü–∏–∫–ª–æ–≤ (~5 –º–∏–Ω—É—Ç)
        """
        while True:
            try:
                if not self.is_learning:
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –ª–æ–≥–∏ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                    patterns = self.analyze_conversation_logs(100)
                    if patterns:
                        self.learn_from_patterns(patterns)
                        self.learning_cycles += 1

                        # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: Auto-save –∫–∞–∂–¥—ã–µ 10 —Ü–∏–∫–ª–æ–≤
                        if self.learning_cycles % 10 == 0:
                            print(f"[Nicole2Nicole] Auto-saving knowledge (cycle {self.learning_cycles})...")
                            self.export_learned_knowledge(self.knowledge_file)

                time.sleep(30)

            except Exception as e:
                print(f"[Nicole2Nicole:ERROR] –û—à–∏–±–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {e}")
                time.sleep(60)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
                
    def start_continuous_learning(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        learning_thread = threading.Thread(target=self.continuous_learning_loop, daemon=True)
        learning_thread.start()
        print("[Nicole2Nicole] –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ")
        
    def get_learning_statistics(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—É—á–µ–Ω–∏—è"""
        return {
            'learned_patterns': len(self.learning_patterns),
            'architecture_preferences': len(self.architecture_preferences),
            'is_learning': self.is_learning,
            'top_patterns': sorted(
                [(k, v['avg_success'], v['frequency']) for k, v in self.learning_patterns.items()],
                key=lambda x: x[1] * x[2],
                reverse=True
            )[:10]
        }
        
    def force_learning_session(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ—Å—Å–∏—é –æ–±—É—á–µ–Ω–∏—è"""
        print("[Nicole2Nicole] –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ...")
        patterns = self.analyze_conversation_logs(500)
        if patterns:
            self.learn_from_patterns(patterns)
            return True
        return False
        
    def export_learned_knowledge(self, filepath: str):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –≤ —Ñ–∞–π–ª"""
        knowledge = {
            'learning_patterns': self.learning_patterns,
            'evolution_patterns': self.evolution_patterns,
            'architecture_preferences': self.architecture_preferences,
            'export_timestamp': time.time()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(knowledge, f, ensure_ascii=False, indent=2)
            
        print(f"[Nicole2Nicole] –ó–Ω–∞–Ω–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filepath}")
        
    def import_learned_knowledge(self, filepath: str):
        """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                knowledge = json.load(f)
                
            self.learning_patterns.update(knowledge.get('learning_patterns', {}))
            self.evolution_patterns.update(knowledge.get('evolution_patterns', {}))
            self.architecture_preferences.update(knowledge.get('architecture_preferences', {}))
            
            print(f"[Nicole2Nicole] –ó–Ω–∞–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ {filepath}")
            return True
            
        except Exception as e:
            print(f"[Nicole2Nicole:ERROR] –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
            return False

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –æ—Å–Ω–æ–≤–Ω–æ–π Nicole —Å–∏—Å—Ç–µ–º–æ–π
class EnhancedFluidTransformer:  # –£–±–∏—Ä–∞–µ–º –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç nicole.FluidTransformer
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä —Å –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º"""
    
    def __init__(self, transformer_id: str, session_context: Dict = None, learning_core = None):
        # –£–±–∏—Ä–∞–µ–º super() –≤—ã–∑–æ–≤
        self.transformer_id = transformer_id
        self.session_context = session_context or {}
        self.learning_core = learning_core
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑—É—á–µ–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        if self.learning_core:
            improved_arch = self.learning_core.suggest_architecture_improvements(
                self.architecture, 
                session_context.get('conversation_context', '')
            )
            self.architecture = improved_arch
            
    def evolve_architecture(self, metrics):
        """–≠–≤–æ–ª—é—Ü–∏—è —Å —É—á–µ—Ç–æ–º –∏–∑—É—á–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        # –°–Ω–∞—á–∞–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —ç–≤–æ–ª—é—Ü–∏—è
        evolved = super().evolve_architecture(metrics)
        
        # –ó–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ–º –∏–∑—É—á–µ–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
        if self.learning_core and evolved:
            learned_improvements = self.learning_core.suggest_architecture_improvements(
                self.architecture,
                ""  # –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            )
            
            # –ú—è–≥–∫–æ –ø—Ä–∏–º–µ–Ω—è–µ–º –∏–∑—É—á–µ–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
            for param, target_val in learned_improvements.items():
                if param in self.architecture and isinstance(target_val, (int, float)):
                    current_val = self.architecture[param]
                    # –î–≤–∏–∂–µ–º—Å—è –Ω–∞ 10% –∫ –∏–∑—É—á–µ–Ω–Ω–æ–º—É –æ–ø—Ç–∏–º—É–º—É
                    self.architecture[param] = current_val * 0.9 + target_val * 0.1
                    
        return evolved
