#!/usr/bin/env python3
"""
Nicole Repo Learning Engine
===========================
–ü–æ–ª—É–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π —Å–ª–æ–π –∞–≤—Ç–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.

–§–ò–õ–û–°–û–§–ò–Ø:
- –ó–∞–º—ã–∫–∞–µ–º –ø–µ—Ç–ª—é: –∫–∞–∂–¥–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –∫–æ–¥–µ/–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Üí –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- SHA256-based –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –¥–∞–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
- –•–∞–≤–∞–µ—Ç markdown, README, –∫–æ–¥ ‚Üí —ç–∫—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- –û–±—É—á–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Nicole2NicoleCore –±–µ–∑ —à–∞–±–ª–æ–Ω–æ–≤
- –†–µ–∑–æ–Ω–∞–Ω—Å –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: –∫–æ–¥ = —á–∞—Å—Ç—å —Å–æ–∑–Ω–∞–Ω–∏—è

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
    from nicole_repo_learner import NicoleRepoLearner

    learner = NicoleRepoLearner(
        repo_path="/path/to/nicole",
        check_interval=60  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
    )
    learner.start()

–ü–æ—Å–≤—è—â–∞–µ—Ç—Å—è –∏–¥–µ–µ –∑–∞–º–∫–Ω—É—Ç–æ–π –ø–µ—Ç–ª–∏ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞.
"""

import hashlib
import logging
import threading
import time
import json
import sqlite3
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º repo_monitor –∫–∞–∫ –±–∞–∑—É
from repo_monitor import RepoWatcher

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Nicole2Nicole –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
try:
    from nicole2nicole import Nicole2NicoleCore
    NICOLE2NICOLE_AVAILABLE = True
except ImportError:
    NICOLE2NICOLE_AVAILABLE = False
    print("[NicoleRepoLearner] ‚ö†Ô∏è Nicole2Nicole –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –æ–±—É—á–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RepoChangeAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–ø–æ –∏ —ç–∫—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""

    def __init__(self):
        self.important_markers = {
            'architecture': ['class ', 'def ', 'async def', 'import ', 'from '],
            'principles': ['# ME –ü–†–ò–ù–¶–ò–ü', '# –†–ï–ó–û–ù–ê–ù–°', '# NO TEMPLATES', '# ANTI-TEMPLATE'],
            'documentation': ['##', '###', 'TODO:', 'FIXME:', 'NOTE:'],
            'philosophy': ['—Ñ–∏–ª–æ—Å–æ—Ñ–∏—è', '–ø—Ä–∏–Ω—Ü–∏–ø', '—Ä–µ–∑–æ–Ω–∞–Ω—Å', '—ç–≤–æ–ª—é—Ü–∏—è', '–º—É—Ç–∞—Ü–∏—è']
        }

    def analyze_file_change(self, file_path: Path) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ —ç–∫—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç –∑–Ω–∞–Ω–∏—è"""
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            analysis = {
                'file_path': str(file_path),
                'file_type': file_path.suffix,
                'timestamp': datetime.now().isoformat(),
                'patterns': [],
                'importance_score': 0.0
            }

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            for category, markers in self.important_markers.items():
                for marker in markers:
                    if marker.lower() in content.lower():
                        analysis['patterns'].append({
                            'category': category,
                            'marker': marker,
                            'context': self._extract_context(content, marker)
                        })
                        analysis['importance_score'] += 0.1

            # –ë–æ–Ω—É—Å –∑–∞ README –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
            if 'README' in file_path.name.upper() or file_path.suffix == '.md':
                analysis['importance_score'] += 0.5

            # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            if file_path.stem in ['nicole', 'h2o', 'high', 'blood', 'nicole_objectivity']:
                analysis['importance_score'] += 0.3

            return analysis

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return {'file_path': str(file_path), 'error': str(e), 'importance_score': 0.0}

    def _extract_context(self, content: str, marker: str, context_lines: int = 3) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –º–∞—Ä–∫–µ—Ä–∞"""
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if marker.lower() in line.lower():
                start = max(0, i - context_lines)
                end = min(len(lines), i + context_lines + 1)
                return '\n'.join(lines[start:end])
        return ""


class NicoleRepoLearner:
    """
    –ì–ª–∞–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ –∞–≤—Ç–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

    –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
    1. RepoWatcher (SHA256) ‚Üí –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
    2. RepoChangeAnalyzer ‚Üí –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
    3. Nicole2NicoleCore ‚Üí –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö
    4. SQLite ‚Üí –ª–æ–≥–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
    """

    def __init__(
        self,
        repo_path: str = ".",
        check_interval: int = 60,
        learning_db: str = "nicole_repo_learning.db",
        auto_learn: bool = True
    ):
        self.repo_path = Path(repo_path)
        self.check_interval = check_interval
        self.learning_db = learning_db
        self.auto_learn = auto_learn

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.analyzer = RepoChangeAnalyzer()
        self.learning_core = None
        if NICOLE2NICOLE_AVAILABLE:
            self.learning_core = Nicole2NicoleCore()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.changes_detected = 0
        self.learning_sessions = 0
        self.last_learning_time = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
        self._init_database()

        # –°–æ–∑–¥–∞–µ–º RepoWatcher —Å –Ω–∞—à–∏–º –∫–æ–ª–ª–±—ç–∫–æ–º
        watched_paths = [self.repo_path]
        extensions = {'.py', '.md', '.txt', '.json', '.yaml', '.yml'}

        self.watcher = RepoWatcher(
            paths=watched_paths,
            on_change=self._on_repo_change,
            exts=extensions,
            interval=check_interval
        )

        logger.info(f"[NicoleRepoLearner] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {repo_path}")
        logger.info(f"[NicoleRepoLearner] –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {check_interval}—Å")
        logger.info(f"[NicoleRepoLearner] –ê–≤—Ç–æ–æ–±—É—á–µ–Ω–∏–µ: {'‚úÖ' if auto_learn else '‚ùå'}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è"""
        conn = sqlite3.connect(self.learning_db)
        cursor = conn.cursor()

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS repo_changes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT NOT NULL,
            file_path TEXT NOT NULL,
            file_type TEXT,
            importance_score REAL,
            patterns TEXT,
            learned BOOLEAN DEFAULT 0
        )
        """)

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS learning_sessions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT NOT NULL,
            changes_count INTEGER,
            patterns_learned INTEGER,
            duration_seconds REAL
        )
        """)

        conn.commit()
        conn.close()
        logger.info(f"[NicoleRepoLearner] –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≥–æ—Ç–æ–≤–∞: {self.learning_db}")

    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        logger.info("[NicoleRepoLearner] üöÄ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...")
        self.watcher.start()
        logger.info("[NicoleRepoLearner] ‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫—Ç–∏–≤–µ–Ω!")

    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        logger.info("[NicoleRepoLearner] –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")
        self.watcher.stop()
        logger.info("[NicoleRepoLearner] ‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    def _on_repo_change(self):
        """–ö–æ–ª–ª–±—ç–∫ –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–µ–ø–æ"""
        self.changes_detected += 1
        logger.info(f"[NicoleRepoLearner] üî• –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã! (–≤—Å–µ–≥–æ: {self.changes_detected})")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        changed_files = self._get_recently_changed_files()

        if not changed_files:
            logger.warning("[NicoleRepoLearner] –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return

        logger.info(f"[NicoleRepoLearner] –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é {len(changed_files)} —Ñ–∞–π–ª–æ–≤...")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        analyses = []
        for file_path in changed_files:
            analysis = self.analyzer.analyze_file_change(file_path)
            analyses.append(analysis)

            # –õ–æ–≥–∏—Ä—É–µ–º –≤ –ë–î
            self._log_change(analysis)

        # –ê–≤—Ç–æ–æ–±—É—á–µ–Ω–∏–µ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if self.auto_learn and self.learning_core:
            self._trigger_learning(analyses)

    def _get_recently_changed_files(self) -> List[Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–¥–∞–≤–Ω–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –º–∏–Ω—É—Ç—ã)"""
        recent_files = []
        cutoff_time = time.time() - 120  # 2 –º–∏–Ω—É—Ç—ã –Ω–∞–∑–∞–¥

        for file_path in self.repo_path.rglob('*'):
            if (file_path.is_file() and
                '.git' not in file_path.parts and
                file_path.suffix in {'.py', '.md', '.txt', '.json'}):
                try:
                    mtime = file_path.stat().st_mtime
                    if mtime > cutoff_time:
                        recent_files.append(file_path)
                except:
                    pass

        return recent_files

    def _log_change(self, analysis: Dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –ë–î"""
        try:
            conn = sqlite3.connect(self.learning_db)
            cursor = conn.cursor()

            cursor.execute("""
            INSERT INTO repo_changes (timestamp, file_path, file_type, importance_score, patterns)
            VALUES (?, ?, ?, ?, ?)
            """, (
                analysis.get('timestamp', datetime.now().isoformat()),
                analysis.get('file_path', 'unknown'),
                analysis.get('file_type', 'unknown'),
                analysis.get('importance_score', 0.0),
                json.dumps(analysis.get('patterns', []))
            ))

            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è: {e}")

    def _trigger_learning(self, analyses: List[Dict]):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–æ–≤"""
        if not self.learning_core:
            logger.warning("[NicoleRepoLearner] Learning core –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        start_time = time.time()
        logger.info("[NicoleRepoLearner] üß† –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö...")

        # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (importance_score > 0.3)
        important_analyses = [a for a in analyses if a.get('importance_score', 0) > 0.3]

        if not important_analyses:
            logger.info("[NicoleRepoLearner] –ù–µ—Ç –≤–∞–∂–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return

        logger.info(f"[NicoleRepoLearner] –û–±—É—á–∞—é—Å—å –Ω–∞ {len(important_analyses)} –≤–∞–∂–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö")

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ–º learning session
        try:
            self.learning_core.force_learning_session()

            duration = time.time() - start_time
            self.learning_sessions += 1
            self.last_learning_time = datetime.now()

            # –õ–æ–≥–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é –æ–±—É—á–µ–Ω–∏—è
            self._log_learning_session(len(important_analyses), duration)

            logger.info(f"[NicoleRepoLearner] ‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {duration:.2f}—Å")

        except Exception as e:
            logger.error(f"[NicoleRepoLearner] –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")

    def _log_learning_session(self, changes_count: int, duration: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Å–µ—Å—Å–∏—é –æ–±—É—á–µ–Ω–∏—è"""
        try:
            conn = sqlite3.connect(self.learning_db)
            cursor = conn.cursor()

            cursor.execute("""
            INSERT INTO learning_sessions (timestamp, changes_count, duration_seconds)
            VALUES (?, ?, ?)
            """, (datetime.now().isoformat(), changes_count, duration))

            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")

    def get_statistics(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã"""
        return {
            'changes_detected': self.changes_detected,
            'learning_sessions': self.learning_sessions,
            'last_learning_time': self.last_learning_time.isoformat() if self.last_learning_time else None,
            'auto_learn_enabled': self.auto_learn,
            'learning_core_available': self.learning_core is not None
        }

    def manual_learning_trigger(self):
        """–†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –≤—Å–µ—Ö –Ω–µ–∏–∑—É—á–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö"""
        logger.info("[NicoleRepoLearner] –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")

        # –ß–∏—Ç–∞–µ–º –Ω–µ–∏–∑—É—á–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–∑ –ë–î
        conn = sqlite3.connect(self.learning_db)
        cursor = conn.cursor()

        cursor.execute("""
        SELECT file_path, importance_score, patterns
        FROM repo_changes
        WHERE learned = 0 AND importance_score > 0.3
        ORDER BY timestamp DESC
        LIMIT 50
        """)

        rows = cursor.fetchall()
        conn.close()

        if not rows:
            logger.info("[NicoleRepoLearner] –ù–µ—Ç –Ω–µ–∏–∑—É—á–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            return

        logger.info(f"[NicoleRepoLearner] –ù–∞–π–¥–µ–Ω–æ {len(rows)} –Ω–µ–∏–∑—É—á–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π")

        # –°–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑—ã –∏–∑ –ë–î
        analyses = [
            {
                'file_path': row[0],
                'importance_score': row[1],
                'patterns': json.loads(row[2]) if row[2] else []
            }
            for row in rows
        ]

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        self._trigger_learning(analyses)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_repo_learner = None


def start_repo_learning(repo_path: str = ".", check_interval: int = 60):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ-learner"""
    global _repo_learner

    if _repo_learner:
        logger.warning("[NicoleRepoLearner] –£–∂–µ –∑–∞–ø—É—â–µ–Ω!")
        return _repo_learner

    _repo_learner = NicoleRepoLearner(
        repo_path=repo_path,
        check_interval=check_interval,
        auto_learn=True
    )
    _repo_learner.start()

    return _repo_learner


def stop_repo_learning():
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ-learner"""
    global _repo_learner

    if _repo_learner:
        _repo_learner.stop()
        _repo_learner = None


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "test":
        print("=== NICOLE REPO LEARNER TEST ===")

        learner = NicoleRepoLearner(
            repo_path=".",
            check_interval=10,  # –ö–æ—Ä–æ—Ç–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Ç–µ—Å—Ç–∞
            auto_learn=True
        )

        print("\n‚úÖ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ 60 —Å–µ–∫—É–Ω–¥...")
        print("   –ò–∑–º–µ–Ω–∏—Ç–µ –ª—é–±–æ–π .py/.md —Ñ–∞–π–ª —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∞–∫—Ü–∏—é!\n")

        learner.start()

        try:
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º 60 —Å–µ–∫—É–Ω–¥
            for i in range(6):
                time.sleep(10)
                stats = learner.get_statistics()
                print(f"[{i*10}s] –ò–∑–º–µ–Ω–µ–Ω–∏–π: {stats['changes_detected']}, "
                      f"–û–±—É—á–µ–Ω–∏–π: {stats['learning_sessions']}")
        except KeyboardInterrupt:
            print("\n\n–û—Å—Ç–∞–Ω–æ–≤–∫–∞...")

        learner.stop()

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = learner.get_statistics()
        print("\n=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
        print(f"–ò–∑–º–µ–Ω–µ–Ω–∏–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {stats['changes_detected']}")
        print(f"–°–µ—Å—Å–∏–π –æ–±—É—á–µ–Ω–∏—è: {stats['learning_sessions']}")
        print(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ: {stats['last_learning_time'] or '–Ω–∏–∫–æ–≥–¥–∞'}")

    else:
        print("Nicole Repo Learning Engine")
        print("–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: python3 nicole_repo_learner.py test")
        print("\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ:")
        print("  from nicole_repo_learner import start_repo_learning")
        print("  learner = start_repo_learning()")
